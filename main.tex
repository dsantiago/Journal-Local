\documentclass[journal,twoside,web]{ieeecolor}
\usepackage{tmi}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage[acronym]{glossaries}

\input{A-acronyms}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
    
\markboth{\journalname, VOL. XX, NO. XX, XXXX 2025}
{Author \MakeLowercase{\textit{et al.}}: PreparationXXX of Papers for IEEE TRANSACTIONS ON MEDICAL IMAGING}

\begin{document}

\title{Magnetic Resonance Imaging Analysis for Cardiomyopathy Classification with Attention Mechanisms Support}

\author{
   Santiago. Diogo, \IEEEmembership{Fellow, IEEE},
   \input{01-thanks}
}

\maketitle

% ---------------------------------------------
\begin{abstract}
The increasing availability of medical imaging exams, such as magnetic resonance imaging, generates a large volume of data, making its analysis complex and challenging. In this scenario, advanced computational approaches can optimize the interpretation of these images and assist in the early diagnosis of cardiovascular diseases. This work aims to unify contemporary approaches in the evaluation of cardiomyopathy. 
With the support of radiomic analysis, which extracts information from statistical and texture characteristics of a medical image, and features derived from a classical neural network for computer vision, such as ResNet50, promising results can combined and obtained. Some forms of attention mechanism are applied including self attention and selective attention using Squeeze and Excitation Nets.  The results confirm that the combination of information from various domains regarding a given patient, when integrated, can lead to more interesting outcomes compared to analyzing data in isolation. This study aims to apply the aforementioned approaches, based on previous literature, in an innovative application for cardiomyopathy testing
% , adapting and proposing a more robust architecture 
% to achieve better results.
\end{abstract}

% ---------------------------------------------
\begin{IEEEkeywords}
Radiomics, Attention Mechanism, Transformers, Cardiomyopathy, Medical Imaging.
\end{IEEEkeywords}


% ---------------------------------------------
\section{Introduction}
\label{sec:introduction}
\IEEEPARstart{S}{ince} the early 2000s, the volume of data generated in medicine has grown exponentially,this rapid growth highlights the need for tools capable of efficiently processing and analyzing vast amounts of information.

Medical imaging techniques, such as \gls{TC} and \gls{MRI}, have become essential in modern medicine, offering detailed three-dimensional representations of human anatomy. These imaging techniques not only improve diagnostic accuracy but also generate large datasets that can be quantitatively analyzed. Concurrently, \gls{AI} has driven significant advancements in diagnostic imaging, enhancing efficiency and precision in medical decision-making.

Deep neural networks have demonstrated high performance in computer vision tasks, including image classification, object detection, and segmentation. Once optimized on a given dataset, these models can extract discriminative features that enhance medical image analysis. Furthermore, transformer architectures, commonly used in autoregressive generative models such as \gls{LLMs}, have gained prominence due to their parallelization capabilities and self-attention mechanisms, which allow models to focus on the most relevant parts of the input data.

Additionally, image processing techniques such as texture analysis have been employed for decades in various medical domains. Radiomics, a powerful approach for extracting quantitative features from medical images, captures patterns that may not be perceptible to the human eye. This methodology has shown potential applications in fields such as oncology and cardiology.

In cardiac imaging analysis, texture-based MRI assessments have been used to evaluate the risk of post-myocardial infarction arrhythmia. Specifically, texture analysis of contrast-enhanced and non-contrast MRI scans in cardiomyopathy patients has been explored for predicting clinical outcomes. Among cardiomyopathies, \gls{HCM} is one of the most prevalent, frequently diagnosed in young and middle-aged individuals. While often asymptomatic, \gls{HCM} can lead to severe conditions such as heart failure and stroke, making early diagnosis crucial in preventing adverse outcomes. In this context, radiomics—which extracts high-dimensional data from medical images, often including texture analysis—holds promise for early diagnosis and risk assessment in cardiomyopathy.

The integration of AI and radiomics represents a promising strategy for detecting cardiomyopathies and other cardiac conditions. Recent studies have demonstrated that combining deep features with radiomic characteristics can significantly improve the predictive performance of diagnostic models for lung cancer using CT imaging. Models leveraging self-attention mechanisms to analyze concatenated data have achieved up to 82.35\% accuracy and an AUC of 0.74.

Thus, this study proposes the implementation and validation of a fusion strategy that combines radiomic and deep learning features with self-attention mechanisms to improve cardiomyopathy classification. Beyond advancing the state-of-the-art in medical diagnosis, this research aims to contribute to the development of more effective and accessible solutions for clinical decision support.


% \IEEEPARstart{T}{his} document is a template for \LaTeX.
% You are encouraged to use it to prepare your manuscript.
% If you are reading a paper or PDF version of this document, please download the 
% \LaTeX .zip file from the IEEE Web site at \underline
% {https://www.embs.org/tmi/authors-instructions/} to prepare your manuscript.
% You can also explore using the Overleaf editor at 
% \underline
% {https://www.overleaf.com/blog/278-how-to-use-overleaf-with-}\discretionary{}{}{}\underline
% {ieee-collabratec-your-quick-guide-to-getting-started\#.}\discretionary{}{}{}\underline{xsVp6tpPkrKM9}

% ---------------------------------------------
\section{Dataset}
Two datasets were used in this study: ACDC and SunnyBrook. Both are publicly available and intended for research purposes. The ACDC dataset consists of 150 images, with 100 for training and 50 for testing, evenly distributed across five classes: DCM, HCM, NOR, MINF, and RV. The SunnyBrook dataset contains 45 images, and to maintain proportional compatibility with ACDC, it was divided into 30 images for training and 15 for testing. The dataset includes the following classes: NOR, IC, IC-I, and HIP. Details about each class are provided in the following sections dedicated to each dataset.

% ------
\subsection{ACDC Dataset}
The ACDC dataset was created using real clinical exams obtained from the University Hospital of Dijon (France). The acquired data was fully anonymized and processed in compliance with the regulations established by the local ethics committee of the Dijon hospital.  

This dataset covers several well-defined pathologies, with a sufficient number of cases to: (1) properly train machine learning methods, and  
(2) clearly evaluate variations in key physiological parameters derived from cine-MRI, particularly diastolic volume and ejection fraction.  

The dataset consists of $150$ exams, $100$ for training and $50$ for test. Each exam is from a different patient and the dataset is divided into five equally distributed subgroups. The five distinct classes are: \gls{DCM}, \gls{HCM}, \gls{NOR}, \gls{MINF}, and \gls{RV}. The \gls{DCM} and \gls{HCM} classes are interpreted as indicative of cardiomyopathy, while \gls{NOR}, \gls{MINF}, and \gls{RV} represent normal heart conditions. Details on these classes can be found in Table \ref{table01}.  

Additionally, the dataset includes segmentation masks, allowing for potential segmentation applications. The label values range from 0 to 3, representing voxels associated with the background (0), right ventricle cavity (1), myocardium (2), and left ventricle cavity (3). Figures 17, 18, and 19 illustrate the images and their respective segmentation masks for \gls{DCM}, \gls{HCM}, and NOR. These masks display three distinct shades of gray corresponding to the described segmentation.


\begin{table}[h]
\centering
\caption{ACDC Labels}
\label{table01}
\setlength{\tabcolsep}{4pt}
% \begin{tabular}{|p{32pt}|p{33pt}|p{72pt}|p{72pt}|}
\begin{tabular}{|c|c|c|c|}
    \hline 
          \textbf{Group} & \textbf{Quantity} & \textbf{W/ Cardiomiopaty} & \textbf{W/O Cardiomiopaty}  \\ 
    \hline 
        NOR & 30 & 0 & 30 \\ 
        DCM & 30 & 30 & 0\\ 
        HCM & 30 & 30 & 0\\ 
        MINF & 30 & 0 & 30 \\ 
        RV & 30 & 0 & 30 \\
    \hline 
        \textbf{Total}: & 150  & 60 & 90\\ 
    \hline 
    \multicolumn{4}{p{230pt}}{ACDC - Redistribution for normal $\times$ cardiomyopathy classification. } \\
\end{tabular} 
\end{table}


% ------
\subsection{SunnyBrook Dataset}
The Sunny dataset, also known as the 2009 Cardiac MR Left Ventricle Segmentation Challenge data, consists of 45 MRI images from a mixed group of patients and pathologies, including healthy individuals, hypertrophy, heart failure with infarction, and heart failure without infarction. There are four pathological groups in this dataset, classified as follows:  

a) Heart failure with infarction (IC-I): Group with an ejection fraction (EF) < 40\% and evidence of late gadolinium enhancement (Gd).  
b) Heart failure without infarction (IC): Group with EF < 40\% and no late gadolinium enhancement.  
c) Left ventricular hypertrophy (HIP): Group with normal EF ($>$ 55\%) and a left ventricular mass-to-body surface area ratio $>$ 83 g/m².  
d) Normal (NOR): Group with EF $>$ 55\% and no hypertrophy.  

For this study, the HIP and NOR classes were used to classify cases of cardiomyopathy and normal conditions, respectively. Table 6 shows the distribution of the 45 patients and the cardiovascular activity values used for patient classification.

% ---------------------------------------------
\section{Methodology}

In this section, first introduce the image preprocessing and feature extraction process, which involves selecting and extracting features from \gls{MRI} images. Then, we introduce the base model, originally applied to \gls{NSCLC} early recurrence prediction. And last, we describe the design of our proposed architecture with a new concatenation, using segmented masks and in addition to using the self-attention mechanism, it was also used selective attention in the form of \gls{SE} Net modules.

The change in the concatenation method was intentional, as the adapted version includes a new convolutional layer that is not present in the original version, aiming to extract relevant information from the fusion of embeddings. The adapted version also adds a selective attention layer in the form of an \gls{SE} block, which precedes the self-attention block.  

Another modification in the adapted version is that the self-attention block is applied $N$ times instead of just once, as in the base work, leading to a noticeable improvement in results. It is important to note that both attention mechanisms serve different purposes: while the selective attention block focuses on the relationships between the embedding channels, the self-attention block efficiently optimizes and weights the fused feature vector.  

The intuition behind applying attention mechanisms with different purposes is inspired by the work of \cite{yangNeuralNetworkDesign2024a}.


% ------
\subsection{Data Preprocessing}

For the preprocessing step, the ACDC dataset was used. The ACDC dataset originally contains five distinct classes and we organized it for a binary cadyomiopathy classification. The set of frames used are defined in the diastolic phase, and the number of frames varies per patient. The radiomic features are extracted using the PyRadiomics library. This tool allows 3D cardiac image volumes and their respective masks to be used as input, extracting manual features related to texture, shape, grayscale intensity, etc.. The result is a vector of $78$ radiomic features.

Deep features are extracted using a ResNet50 network, excluding the final classification layer. This process is applied to each slice of the 3D volume for both the cardiac image and its corresponding mask, resulting in feature vectors of size $100,352$. Following the base model's methodology, an F-Test is applied to reduce the dimensionality from: deep features from 100,352 to 27,372 and radiomic features from 78 to $\text{EMBED}_{size} \in \{24, 48, 64\}$.

The $\text{EMBED}_{size}$ value varies in the adapted versions, serving as a hyperparameter, ensuring that all embeddings have the same size. Feature concatenation is performed: In the last dimension for the original model and its variations and in the first dimension for adapted versions. It is important to note that, unlike the base model version, which contains only one deep feature vector, the adapted versions may include an additional vector corresponding to the mask with the region of interest.

% ------
\subsection{Base Model}

The work from Ai et al (2023) proposed a deep learning based on self-attention mechanism for \gls{NSCLC} early recurrence prediction. Firstly radiomics was applied using diverse machine learning techniques to extract handcrafted features from \gls{CT} images, encompassing texture, shape, grayscale, etc. Radiomics-based methods mainly rely on handcrafted design to extract numerous quantitative  features from \gls{CT} images, including tumor shape, size, density,  texture, edge, etc \cite{aiSelfAttentionBasedFusion2023}

Subsequently, a pre-trained ResNet50 network was utilized to extract deep features that encapsulate high-level semantic and representation information from the \gls{CT} images. These features were then fused into a unified feature vector and a self attention module was applied ending with a classification layer for the \gls{NSCLC} early recurrence prediction \cite{aiSelfAttentionBasedFusion2023}. The architecture can be seen in Figure \ref{fig01}.


\begin{figure}[h]
\centerline{\includegraphics[width=\columnwidth]{figures/fig01.png}}
\caption{Proposed  Architecture for \gls{NSCLC} early recurrence prediction. First radiomic and deep features are extracrted, a F1-Test reduces their dimensions that are concatenated and sent ao a self-attention module.}
\label{fig01}
\end{figure}

% ------
\subsection{Proposed Model}

The schematic of the proposed architecture is shown in Figure \ref{fig02}. Deep features are extracted from the images and masks using ResNet50 and undergo a linear transformation to a size of $27,372$, as per the base model. Radiomic features are extracted by applying various statistical models, resulting in 78 features.

An F-Test set is applied to the feature vectors to ensure they have the same size, which is determined by the $\text{EMBED}_{size}$ parameter. The selected features are then concatenated and passed through the convolution module, which consists of a 1D convolution, an \gls{SE} block, and another 1D convolution. The first convolution converts the number of channels to $16$, the SE block maintains the dimensionality, and the second convolution reduces the channels from $16$ to $1$. The process continues through the self-attention module, and finally, a linear layer with a single neuron performs binary classification.


\begin{figure}[h]
\centerline{\includegraphics[width=\columnwidth]{figures/fig02.png}}
\caption{Proposed Architecture for cardiomyopathy classification. The concatenation are made in the channels dimension. There major difference are the addition of the heart mask, and the SE Module.}
\label{fig02}
\end{figure}

% ------
\subsection{Selective Attention Module}

Selective attention plays a crucial role in improving the performance of deep learning models by allowing them to focus on the most relevant features in their internal representations. Specifically, the \gls{SE} block is designed to adaptively recalibrate feature channels by assigning higher weights to the most informative characteristics. This mechanism operates in two main steps: first, it reduces the dimensionality of global features (squeeze) to capture overall context, and then it applies an excitation mechanism to adjust the weights of each channel based on their relative importance. By integrating \gls{SE} blocks into an architecture, the model enhances its ability to discriminate relevant patterns while suppressing noise or irrelevant information, leading to greater accuracy and efficiency in data processing \cite{yangNeuralNetworkDesign2024a}.

Since the \gls{SE} block is added only in the adapted version to improve results, the resulting concatenated vector is $3 \times 64$, assuming $\text{EMBED}_{size}= 64$ and the inclusion of the mask. A 1D convolutional layer is applied with $16$ channels, a kernel size of $3$, a stride of $1$, and padding of $1$ to maintain the original dimensions after processing.  

With $16$ channels as the output of the first convolution, the \gls{SE} block is applied to identify the most relevant channels and rescale the original input. The SE block has a reduction parameter $r$, which was set to $16$, as suggested by the authors of the original study. Finally, another 1D convolution is applied with a single output channel, resulting in a one-dimensional vector, which serves as input for the next block, the self-attention module.

% ------
\subsection{Self-Attention Module}

The self-attention mechanism was employed to learn the importance of each feature and capture long-range dependencies. As illustrated in Figure \ref{fig02}, the self-attention module is used to map a query ($Q$), key ($K$), and value ($V$) into an attention-weighted value.  

The model uses 24 concatenated features $F_{hd}$ in the original version and $\text{EMBED}_{size}$ features in the adapted versions. From the resulting vector, each feature is projected onto three learnable matrices: key matrix ($K$), query matrix ($Q$), and value matrix ($V$) through dot-product operations with their corresponding weight matrices $W_{Q}$, $W_{K}$, and $W_{V}$. Consequently, the values $Q$, $K$, and $V$ are defined as $W_{Q}F_{gd}$, $W_{K}F_{gd}$, and $W_{V}F_{gd}$, respectively, where $W_{Q}$, $W_{K}$, and $W_{V}$ represent the linear transformations applied to generate the matrices $Q$, $K$, and $V$ \cite{vaswaniAttentionAllYou2023}.  

The self-attention module is defined in Equation \ref{eq:attention}, where $d_{k}$ represents the dimension of $K$. Without requiring recurrent or convolutional operations, the self-attention module can model long-term dependencies between input features. This module adaptively computes feature weights based on their importance and relevance, enhancing the associations between radiomic and deep features \cite{vaswaniAttentionAllYou2023}.  

This process strengthens the expressive power of the fused features and enables the model to focus more precisely on the most informative features, assisting in medical image diagnosis while reducing the influence of irrelevant features in prediction. Additionally, the model can dynamically allocate attention to different cardiac MRI (\gls{MRI}) image samples, allowing for better adaptation to the feature representations of different cases, improving both accuracy and generalization.  

The loss function used in the model is the binary cross-entropy denoted by the Equation \ref{eq:bce}. Here, $\mathcal{L}_{bce}$ denotes \gls{BCE}, $N$ represents the number of cardiac \gls{MRI}, $r$ denotes the target class of cardiomyopathy, and $\hat{r}$ is the predicted value by the model. A value of 1 indicates the presence of cardiomyopathy, while 0 indicates its absence.

\begin{equation}
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\label{eq:attention}
\end{equation}

\begin{equation}
\mathcal{L}_{bce} = -\frac{1}{N} \sum_{i=1}^N
(r_i \ln \hat{r}_i + (1 - r_i) \ln (1 - \hat{r}_i))
\label{eq:bce}
\end{equation}


% ---------------------------------------------
\section{Results}

This chapter presents the results of the proof of concept conducted with the developed algorithms, including both the baseline model and the adapted models, with the goal of comparing them to the objectives outlined in this dissertation. The tests performed aim to evaluate the algorithm's efficiency under the various adaptations discussed.

% ------
\subsection{Experiments Base Model}

A proof of concept was conducted on the ACDC dataset using the baseline model for an initial evaluation, which was also used as the baseline reference. The baseline model was implemented according to the original paper, and its implementation is shown in Figure \ref{fig01}.  

The training dataset consists of $100$ patient exams, considering only image slices from the diastolic phase. First-order features were extracted using the \textit{PyRadiomics} library, resulting in 78 values that compose the radiomic features.  

For deep feature extraction, a frozen ResNet50 network was used, excluding its final linear layer, which was originally responsible for classifying $1,000$ classes from the ImageNet dataset. The final output was a feature vector containing $100,352$ deep features.  

In this experiment, the model was trained using binary cross-entropy as the objective function, a learning rate of 0.0001, the Adam optimizer, a batch size of 1, and approximately 60 epochs. During training, it was observed that the error stabilized over time. Additionally, a data randomization strategy was employed during training. Finally, the sigmoid function was applied to the output vector of the model so we a probability result between $0$ and $1$. For the classification, it was considered that values above $0,5$ are considered cardiomyopathy and value below or equal $0,5$ are considered normal cases.

% ------
\subsection{Experiments Adapted Model}

The adapted models represent modifications derived from the baseline model, aiming to evaluate whether changes either in hyperparameters or in architectural components can yield promising improvements over the baseline results. These modifications can be categorized as follows:  

\begin{enumerate}  

\item Changes to $\text{EMBED}_{size}$, where the values $[24, 48, 64]$ were tested in an attempt to preserve more of the original information.  

\item In the adapted versions, the respective masks are also incorporated and later concatenated with the radiomic and deep features.  

\item The concatenation process differs from the original model. For instance, assuming $\text{EMBED}_{size} = 12$, the original version produces a $1\times24$ output, whereas in the adapted version, concatenation is performed along the first dimension, resulting in a $2\times12$ output. This adjustment is made because the adapted model introduces a new convolutional block, consisting of a convolution operation and \gls{SE} blocks.  

\end{enumerate}  

The remaining architecture follows the original design, except that the self-attention block can be applied $N$ times. This means its output is recursively fed back as input $N$ times, making $N$ a tunable hyperparameter in the experiment. The tested values for $N$ were $[1, 2, 4, 6]$. These changes do not alter the overall structure of the initial architecture but allow the self-attention module to be executed $N$ times, as proposed in \cite{vaswaniAttentionAllYou2023}. 


% ---------------------------------------------
\section{Conclusion}

This work was made with help of the University FEI.

\appendices

\section*{Acknowledgment}
The preferred spelling of the word ``acknowledgment'' in American English is 
without an ``e'' after the ``g.'' Use the singular heading even if you have 
many acknowledgments. Avoid expressions such as ``One of us (S.B.A.) would 
like to thank $\ldots$ .'' Instead, write ``F. A. Author thanks $\ldots$ .'' In most 
cases, sponsor and financial support acknowledgments are placed in the 
unnumbered footnote on the first page, not here.

\section*{References and Footnotes}
\subsection{References}
% \input{09-refs}

% \bibliographystyle{IEEEtranN}
\bibliographystyle{plain}
\bibliography{refs}

\end{document}
